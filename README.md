ğŸ“° AI-Based Fake News & Misinformation Detection System
ğŸ“Œ Project Overview

The rapid growth of social media has accelerated information sharing worldwide. However, this has also led to the widespread circulation of fake news and misinformation, which can influence public opinion, disrupt elections, create panic, and harm social stability.

This project presents an AI-powered Fake News Detection System that automatically classifies news articles as REAL or FAKE, highlights suspicious phrases, and generates credibility explanations.

ğŸ¯ Project Objectives

The system is designed to:

âœ… Accept a news article as input

âœ… Classify it as REAL or FAKE

âœ… Provide a confidence score

âœ… Highlight suspicious words/phrases (Explainable AI using LIME)

âœ… Generate a credibility explanation

âœ… Display model evaluation metrics

ğŸ§  Technologies Used

Python

Natural Language Processing (NLP)

TF-IDF Vectorization

Logistic Regression

Explainable AI (LIME)

Scikit-learn

Pandas & NumPy

ğŸ“‚ Dataset

Dataset used:

Kaggle â€“ Fake and Real News Dataset

It contains:

True.csv â†’ Real news articles

Fake.csv â†’ Fake news articles

âš™ï¸ System Architecture
Input News Article
        â†“
Text Preprocessing
        â†“
TF-IDF Vectorization
        â†“
Logistic Regression Classifier
        â†“
Prediction (REAL / FAKE)
        â†“
Confidence Score
        â†“
LIME Explanation (Highlighted Phrases)
        â†“
Generated Credibility Explanation

ğŸš€ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/fake-news-detection.git
cd fake-news-detection

2ï¸âƒ£ Install Required Libraries
pip install pandas numpy scikit-learn lime

3ï¸âƒ£ Place Dataset Files

Make sure the dataset files are inside:

/content/sample_data/


Or update file paths in the code accordingly.

4ï¸âƒ£ Run the Project
python fake_news_detection.py

ğŸ“Š Model Evaluation Metrics

The model outputs:

Accuracy

Precision

Recall

F1-Score

Example:

Accuracy  : 0.9852
Precision : 0.9821
Recall    : 0.9875
F1 Score  : 0.9848

ğŸ§ª Sample Model Interaction
ğŸ”¹ Sample Input
Scientists have confirmed that drinking hot lemon water completely cures cancer within two weeks.

ğŸ”¹ Output
Prediction            : FAKE
Confidence Score      : 96.45 %
Suspicious Phrases    : ['completely cures', 'confirmed', 'within two weeks']
Generated Explanation : The article is classified as FAKE with high confidence...

ğŸ” Explainable AI (LIME)

The project integrates LIME (Local Interpretable Model-agnostic Explanations) to:

Identify key influential words

Highlight suspicious phrases

Improve transparency of predictions

This ensures the model is interpretable and trustworthy.

ğŸ“ˆ Key Features

âœ” Automated fake news detection
âœ” Confidence-based classification
âœ” Explainable AI integration
âœ” User input testing interface
âœ” Robust CSV parsing (handles corrupted rows)
âœ” Clean modular code structure

ğŸ“Œ Future Improvements

ğŸ”¥ Upgrade to BERT / Transformer-based model

ğŸ”¥ Deploy as a Web Application (Flask/Streamlit)

ğŸ”¥ Add live news API integration

ğŸ”¥ Multi-language support

ğŸ”¥ Deep learning model (LSTM/GRU)

ğŸ‘¨â€ğŸ’» Author

Fayas Mohammed
B.Tech Graduate | AI & ML Enthusiast

ğŸ“œ License

This project is for academic and educational purposes.
